# -*- coding: utf-8 -*-
"""Data_Normalization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ujo7lUcmGX92HOWooYmFw_pSsn2YyG44

Loading the California Housing  Dataset and visualizing statistics (using pandas)

https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling
"""

import pandas as pd
from sklearn.datasets import fetch_california_housing

# Load the California housing dataset
dataset = fetch_california_housing()
X_full, y_full = dataset.data, dataset.target
feature_names = dataset.feature_names

# Access the target variable (data labels)
target = dataset.target
target_names = dataset.target_names

# Print the name of the target variable
print("target_names")
print(target_names)
# Print the feature names
print("Feature Names:")
print(feature_names)


df = pd.DataFrame(X_full, columns=feature_names)


# Calculate statistics for each feature using the describe() function
statistics = df.describe()

# Display the statistics for each feature
print(statistics)

import pandas as pd
from sklearn.datasets import fetch_california_housing

# Load the California housing dataset
dataset = fetch_california_housing()
X_full, y_full = dataset.data, dataset.target
feature_names = dataset.feature_names

# Select the desired features
features = ["MedInc", "AveOccup"]
features_idx = [list(feature_names).index(feature) for feature in features]
X = X_full[:, features_idx]

# Create a pandas DataFrame with the selected features
df = pd.DataFrame(X, columns=features)


# Calculate statistics for each feature using the describe() function
statistics = df.describe()

# Display the statistics for each feature
print(statistics)

"""Loading the California Housing  Dataset and visualizing statistics (without using pandas)"""

# based on https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py
import matplotlib as mpl
import numpy as np
from matplotlib import cm
from matplotlib import pyplot as plt

from sklearn.datasets import fetch_california_housing



dataset = fetch_california_housing()
X_full, y_full = dataset.data, dataset.target
feature_names = dataset.feature_names

feature_mapping = {
    "MedInc": "Median income in block",
    "HouseAge": "Median house age in block",
    "AveRooms": "Average number of rooms",
    "AveBedrms": "Average number of bedrooms",
    "Population": "Block population",
    "AveOccup": "Average house occupancy",
    "Latitude": "House block latitude",
    "Longitude": "House block longitude",
}
features = ["MedInc", "AveOccup"]
features_idx = [feature_names.index(feature) for feature in features]
X = X_full[:, features_idx]

means = np.mean(X, axis=0)
stds = np.std(X, axis=0)
percentiles_25 = np.percentile(X, 25, axis=0)
percentiles_50 = np.percentile(X, 50, axis=0)
percentiles_75 = np.percentile(X, 75, axis=0)

maximums = np.max(X, axis=0)
minimums = np.min(X, axis=0)

# Display the statistics for each feature
for i, feature in enumerate(features):
    print("Feature:", feature)
    print("Mean:", means[i])
    print("Standard Deviation:", stds[i])
    print("25th Percentile:", percentiles_25[i])
    print("50th Percentile (Median):", percentiles_50[i])
    print("75th Percentile:", percentiles_75[i])
    print("Maximum:", maximums[i])
    print("Minimum:", minimums[i])
    print("-" * 40)

"""Visualizing data after and before the normalization"""

import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import MinMaxScaler
# Load the California housing dataset
dataset = fetch_california_housing()
X_full, y_full = dataset.data, dataset.target
feature_names = dataset.feature_names

# Select the desired features
features = ["MedInc", "AveOccup"]
features_idx = [list(feature_names).index(feature) for feature in features]
X = X_full[:, features_idx]
df = pd.DataFrame(X_full, columns=feature_names)
# Initialize the MinMaxScaler
scaler = MinMaxScaler()

# Apply Min-Max Scaling to the selected features
X_scaled = scaler.fit_transform(X)

# Plot the data before and after normalization
plt.figure(figsize=(10, 5))

# Plot the data before normalization
plt.subplot(1, 2, 1)
plt.scatter(df["MedInc"], df["AveOccup"])
plt.xlabel("Median Income")
plt.ylabel("Average Occupancy")
plt.title("Data Before Normalization")

# Plot the data after normalization
plt.subplot(1, 2, 2)
plt.scatter(X_scaled[:, 0], X_scaled[:, 1])
plt.xlabel("Normalized Median Income")
plt.ylabel("Normalized Average Occupancy")
plt.title("Data After Min-Max Scaling")

plt.tight_layout()
plt.show()

df_scaled = pd.DataFrame(X_scaled, columns=features)
statistics = df_scaled.describe()
pd.options.display.float_format = '{:.3f}'.format
# Display the statistics for each feature
print(statistics)

X_MinMaxScaler=X_scaled

# Plot the data before and after normalization
plt.figure(figsize=(10, 5))


# Plot the data after normalization
plt.subplot(1, 2, 2)
plt.scatter(X_MinMaxScaler[:, 0], X_MinMaxScaler[:, 1])
plt.xlabel("Normalized Median Income")
plt.ylabel("Normalized Average Occupancy")
plt.title("Data After MinMaxScaler")
plt.ylim(-0.01, 0.05)  # Set the y-axis limits for zooming
plt.xlim(-0.1, 1.1)  # Set the x-axis limits for zooming
plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import StandardScaler

# Load the California housing dataset
dataset = fetch_california_housing()
X_full, y_full = dataset.data, dataset.target
feature_names = dataset.feature_names

# Select the desired features
features = ["MedInc", "AveOccup"]
features_idx = [list(feature_names).index(feature) for feature in features]
X = X_full[:, features_idx]
df = pd.DataFrame(X_full, columns=feature_names)

# Initialize the StandardScaler
scaler = StandardScaler()

# Apply StandardScaler Scaling to the selected features
X_scaled = scaler.fit_transform(X)

# Plot the data before and after normalization
plt.figure(figsize=(10, 5))

# Plot the data before normalization
plt.subplot(1, 2, 1)
plt.scatter(df["MedInc"], df["AveOccup"])
plt.xlabel("Median Income")
plt.ylabel("Average Occupancy")
plt.title("Data Before Normalization")

# Plot the data after normalization
plt.subplot(1, 2, 2)
plt.scatter(X_scaled[:, 0], X_scaled[:, 1])
plt.xlabel("Normalized Median Income")
plt.ylabel("Normalized Average Occupancy")
plt.title("Data After StandardScaler")

plt.tight_layout()
plt.show()


df_scaled = pd.DataFrame(X_scaled, columns=features)
statistics = df_scaled.describe()

pd.options.display.float_format = '{:.3f}'.format

# Display the statistics for each feature
print(statistics)

X_StandardScaler=X_scaled

# Plot the data before and after normalization
plt.figure(figsize=(10, 5))


# Plot the data after normalization
plt.subplot(1, 2, 2)
plt.scatter(X_StandardScaler[:, 0], X_StandardScaler[:, 1])
plt.xlabel("Normalized Median Income")
plt.ylabel("Normalized Average Occupancy")
plt.title("Data After StandardScaler")
plt.ylim(-0.3, 0.3)  # Set the x-axis limits for zooming
plt.xlim(-2.1, 4.4)  # Set the y-axis limits for zooming
plt.tight_layout()
plt.show()

"""Scale features using statistics that are robust to outliers.

It involves eliminating the median and rescaling the data based on the interquartile range (IQR), which is the range between the 25th and 75th percentiles (1st quartile and 3rd quartile, respectively).

https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler

"""

import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import RobustScaler

# Load the California housing dataset
dataset = fetch_california_housing()
X_full, y_full = dataset.data, dataset.target
feature_names = dataset.feature_names

# Select the desired features
features = ["MedInc", "AveOccup"]
features_idx = [list(feature_names).index(feature) for feature in features]
X = X_full[:, features_idx]
df = pd.DataFrame(X_full, columns=feature_names)
# Initialize the RobustScaler
scaler = RobustScaler(quantile_range=(25, 75))


# Apply RobustScaler Scaling to the selected features
X_scaled = scaler.fit_transform(X)

# Plot the data before and after normalization
plt.figure(figsize=(10, 5))

# Plot the data before normalization
plt.subplot(1, 2, 1)
plt.scatter(df["MedInc"], df["AveOccup"])
plt.xlabel("Median Income")
plt.ylabel("Average Occupancy")
plt.title("Data Before Normalization")

# Plot the data after normalization
plt.subplot(1, 2, 2)
plt.scatter(X_scaled[:, 0], X_scaled[:, 1])
plt.xlabel("Normalized Median Income")
plt.ylabel("Normalized Average Occupancy")
plt.title("Data After RobustScaler")

plt.tight_layout()
plt.show()


df_scaled = pd.DataFrame(X_scaled, columns=features)
statistics = df_scaled.describe()

pd.options.display.float_format = '{:.3f}'.format

# Display the statistics for each feature
print(statistics)

X_RobustScaler=X_scaled

# Plot the data before and after normalization
plt.figure(figsize=(10, 5))


# Plot the data after normalization
plt.subplot(1, 2, 2)
plt.scatter(X_RobustScaler[:, 0], X_RobustScaler[:, 1])
plt.xlabel("Normalized Median Income")
plt.ylabel("Normalized Average Occupancy")
plt.title("Data After RobustScaler")
plt.ylim(-2, 4)  # Set the y-axis limits for zooming
plt.xlim(-2, 4)  # Set the x-axis limits for zooming
plt.tight_layout()
plt.show()

# Plot the data after different scaling methods
plt.figure(figsize=(15, 5))

# Plot the data after Min-Max Scaling
plt.subplot(1, 3, 1)
plt.scatter(X_MinMaxScaler[:, 0], X_MinMaxScaler[:, 1])
plt.xlim(-5, 5)  # Set the x-axis limits for zooming
plt.ylim(-5, 5)  # Set the y-axis limits for zooming
plt.xlabel("Normalized Median Income")
plt.ylabel("Normalized Average Occupancy")
plt.title("Data After Min-Max Scaling")

# Plot the data after Standard Scaling
plt.subplot(1, 3, 2)
plt.scatter(X_StandardScaler[:, 0], X_StandardScaler[:, 1])
plt.xlim(-5, 5)  # Set the x-axis limits for zooming
plt.ylim(-5, 5)  # Set the y-axis limits for zooming
plt.xlabel("Standardized Median Income")
plt.ylabel("Standardized Average Occupancy")
plt.title("Data After Standard Scaling")

# Plot the data after Robust Scaling
plt.subplot(1, 3, 3)
plt.scatter(X_RobustScaler[:, 0], X_RobustScaler[:, 1])
plt.xlim(-5, 5)  # Set the x-axis limits for zooming
plt.ylim(-5, 5)  # Set the y-axis limits for zooming
plt.xlabel("Robustly Scaled Median Income")
plt.ylabel("Robustly Scaled Average Occupancy")
plt.title("Data After Robust Scaling")

plt.tight_layout()
plt.show()

"""QuantileTransformer (uniform output)"""

import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import QuantileTransformer

# Load the California housing dataset
dataset = fetch_california_housing()
X_full, y_full = dataset.data, dataset.target
feature_names = dataset.feature_names

# Select the desired features
features = ["MedInc", "AveOccup"]
features_idx = [list(feature_names).index(feature) for feature in features]
X = X_full[:, features_idx]
df = pd.DataFrame(X_full, columns=feature_names)
# Initialize the Scaler
scaler =  QuantileTransformer(output_distribution="uniform")

# Apply Scaling to the selected features
X_scaled = scaler.fit_transform(X)

# Plot the data before and after normalization
plt.figure(figsize=(10, 5))

# Plot the data before normalization
plt.subplot(1, 2, 1)
plt.scatter(df["MedInc"], df["AveOccup"])
plt.xlabel("Median Income")
plt.ylabel("Average Occupancy")
plt.title("Data Before Normalization")

# Plot the data after normalization
plt.subplot(1, 2, 2)
plt.scatter(X_scaled[:, 0], X_scaled[:, 1])
plt.xlabel("Normalized Median Income")
plt.ylabel("Normalized Average Occupancy")
plt.title("Data After Quantile Transformer Scaling (Uniform)")

plt.tight_layout()
plt.show()

df_scaled = pd.DataFrame(X_scaled, columns=features)
statistics = df_scaled.describe()
pd.options.display.float_format = '{:.3f}'.format
# Display the statistics for each feature
print(statistics)

X_QuantileTransformer=X_scaled

import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import QuantileTransformer

# Load the California housing dataset
dataset = fetch_california_housing()
X_full, y_full = dataset.data, dataset.target
feature_names = dataset.feature_names

# Select the desired features
features = ["MedInc", "AveOccup"]
features_idx = [list(feature_names).index(feature) for feature in features]
X = X_full[:, features_idx]
df = pd.DataFrame(X_full, columns=feature_names)
# Initialize the Scaler
scaler =  QuantileTransformer(output_distribution="normal")

# Apply Scaling to the selected features
X_scaled = scaler.fit_transform(X)

# Plot the data before and after normalization
plt.figure(figsize=(10, 5))

# Plot the data before normalization
plt.subplot(1, 2, 1)
plt.scatter(df["MedInc"], df["AveOccup"])
plt.xlabel("Median Income")
plt.ylabel("Average Occupancy")
plt.title("Data Before Normalization")

# Plot the data after normalization
plt.subplot(1, 2, 2)
plt.scatter(X_scaled[:, 0], X_scaled[:, 1])
plt.xlabel("Normalized Median Income")
plt.ylabel("Normalized Average Occupancy")
plt.title("Data After Quantile Transformer Scaling (Normal)")

plt.tight_layout()
plt.show()

df_scaled = pd.DataFrame(X_scaled, columns=features)
statistics = df_scaled.describe()
pd.options.display.float_format = '{:.3f}'.format
# Display the statistics for each feature
print(statistics)

X_QuantileTransformer=X_scaled